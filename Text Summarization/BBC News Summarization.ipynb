{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77fdba01",
   "metadata": {},
   "source": [
    "pick article  \n",
    "split into sentences  \n",
    "TF-IDF -> input  \n",
    "score each sentences  \n",
    "sort score in decending order  \n",
    "print the top scoring sentences as the summary"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a1a0e4e",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d684558d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv('bbc_text_cls.csv')\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91badfa",
   "metadata": {},
   "source": [
    "#### Use the first article as an example"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef3b69d3",
   "metadata": {},
   "source": [
    "article = raw.loc[0]['text']\n",
    "article"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8adcdad5",
   "metadata": {},
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e14fa44",
   "metadata": {},
   "source": [
    "sentences = sent_tokenize(article)\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "529a19ca",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8899fa4a",
   "metadata": {},
   "source": [
    "tfidf = TfidfVectorizer(max_features=2000)\n",
    "X = tfidf.fit_transform(sentences)\n",
    "X"
   ]
  },
  {
   "cell_type": "raw",
   "id": "498b1ce6",
   "metadata": {},
   "source": [
    "def non_zero_mean(np_arr):\n",
    "    exist = (np_arr != 0)\n",
    "    num = np_arr.sum(axis = 1)\n",
    "    den = exist.sum(axis = 1)\n",
    "    return num/den"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a02cbca",
   "metadata": {},
   "source": [
    "ranking = pd.DataFrame(non_zero_mean(X))\n",
    "ranking"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f7b8ab5",
   "metadata": {},
   "source": [
    "top_idx = (-ranking.loc[:, 0]).argsort()[0]\n",
    "top_idx"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34720997",
   "metadata": {},
   "source": [
    "summary = sentences[top_idx]\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58a0d02",
   "metadata": {},
   "source": [
    "#### General Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "53264106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textwrap\n",
    "import nltk\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "23b7e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help print the results more nicely\n",
    "def wrap(x):\n",
    "    return textwrap.fill(x, reshape_whitespace = False, fix_sentence_endings = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ce432a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_zero_mean(np_arr):\n",
    "    exist = (np_arr != 0)\n",
    "    num = np_arr.sum(axis = 1)\n",
    "    den = exist.sum(axis = 1)\n",
    "    return num/den\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=stopwords.words('english'),\n",
    "                        norm='l1') \n",
    "#normalization to elimilate the bias of long sentence\n",
    "#as long sentences may contain more words and thus have higher scores\n",
    "\n",
    "#i is the number of article in the dataset\n",
    "def summary(i):\n",
    "    article = raw.loc[i]['text']\n",
    "    sentences = sent_tokenize(article.split('\\n',1)[1]) #remove the title\n",
    "    X = tfidf.fit_transform(sentences)\n",
    "    ranking = pd.DataFrame(non_zero_mean(X))\n",
    "    top_idx = (-ranking.loc[:, 0]).argsort()[0]\n",
    "    print('Summary:', sentences[top_idx])\n",
    "    #compare with title\n",
    "    print('Title:', article.split('\\n',1)[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f446a13d",
   "metadata": {},
   "source": [
    "#method 2 of calculation non-zero means\n",
    "def get_sentence_score(X):\n",
    "    x = sentences[X != 0]\n",
    "    return x.mean\n",
    "\n",
    "scores = np.zeros(len(sents))\n",
    "for i in range(len(sents)):\n",
    "    score = get_sentence_score(X[i,:])\n",
    "    score[i] = score\n",
    "    \n",
    "sort_idx = np.argsort(-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6f56b3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: But its own internet business, AOL, had has mixed fortunes.\n",
      "Title: Ad sales boost Time Warner profit\n"
     ]
    }
   ],
   "source": [
    "summary(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "79ba0605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The government was keen to play down the worrying implications of the data.\n",
      "Title: Japan narrowly escapes recession\n"
     ]
    }
   ],
   "source": [
    "summary(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "98ff29d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: This is because of possible malfunctions with the braking systems.\n",
      "Title: Safety alert as GM recalls cars\n"
     ]
    }
   ],
   "source": [
    "summary(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b76de81",
   "metadata": {},
   "source": [
    "#### Compare with input library methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5952a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f9e7c025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<Sentence: It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband.>, <Sentence: But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results.>, <Sentence: It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue.>)\n"
     ]
    }
   ],
   "source": [
    "summarizer = TextRankSummarizer()\n",
    "parser = PlaintextParser.from_string(\n",
    "    raw.loc[0]['text'].split(\"\\n\",1)[1],\n",
    "    Tokenizer(\"english\"))\n",
    "summary = summarizer(parser.document, sentences_count= 3)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "25b762c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<Sentence: Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.>, <Sentence: Time Warner said on Friday that it now owns 8% of search-engine Google.>, <Sentence: For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn.>)\n"
     ]
    }
   ],
   "source": [
    "summarizer = LsaSummarizer()\n",
    "summary = summarizer(parser.document, sentences_count= 3)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0354bd8f",
   "metadata": {},
   "source": [
    "from gensim.summarization.summarizer import summarize\n",
    "summary = summarize(raw.loc[0]['text'].split(\"\\n\",1)[1])\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "45cfbe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gensim\n",
      "Version: 4.2.0\n",
      "Summary: Python framework for fast Vector Space Modelling\n",
      "Home-page: http://radimrehurek.com/gensim\n",
      "Author: Radim Rehurek\n",
      "Author-email: me@radimrehurek.com\n",
      "License: LGPL-2.1-only\n",
      "Location: /opt/anaconda3/lib/python3.9/site-packages\n",
      "Requires: scipy, smart-open, numpy\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show gensim #old version < 3.8 works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c0f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
